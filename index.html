<!DOCTYPE html>
<html>
<head>
  <title>Tema 1</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      height: 100vh;
      background-color: #f0f0f0;
    }
    .window {
      background-color: rgb(204, 161, 222);
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      width: 1000px;
      text-align: center;
    }
    
    .content {
      margin-top: 20px;
    }

    hr {
      border: none;
      height: 1px;
      background-color: #9aadee; /* Color de la línea */
      margin: 20px 0; /* Espacio arriba y abajo */
    }

    .resaltado {
      background-color: rgb(242, 173, 237);
      font-weight: bold;
  }

  hr {
    border: none;
    height: 1px;
    background-color: #9aadee; /* Color de la línea */
    margin: 20px 0; /* Espacio arriba y abajo */
  }


  .index-container {
    background-color: #f0bfe8;
    padding: 40px;
    border-radius: 10px;
    box-shadow: 0 6px 15px rgba(0, 0, 0, 0.1);
    width: 400px;
    margin: 0 auto;
    text-align: center;
  }

  .index-title {
    font-size: 28px;
    font-weight: bold;
    margin-bottom: 25px;
  }

  .index-list {
    list-style-type: none;
    margin: 0;
    padding: 0;
    text-align: left;
  }

  .index-list li {
    margin-bottom: 15px;
  }

  .index-list a {
    color: #6200ee;
    text-decoration: none;
  }

  .index-list a:hover {
    text-decoration: underline;
  }


  </style>
</head>
<body>


  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>


  <span class="resaltado">Usuario de Dataquest.</span> <a href="https://app.dataquest.io/profile/230110264">Acceder</a>

  <hr>

</body>
<div class="index-container">
  <h2 class="index-title">Índice</h2>
  <ul class="index-list">
    <li><a href="#tema1">Tema 1</a></li>
    <li><a href="#tema2">Tema 2</a></li>
    <li><a href="#tema3">Tema 3</a></li>
    <li><a href="#tema4">Tema 4</a></li>
    <li><a href="#tema5">Tema 5</a></li>
  </ul>
</div>

<br>
<br>
<br>
<br>
<br>
  
  <div class="window">

    <h1 id="tema1">Tema 1</h1>

    <div class="content">
      <!-- Aquí puedes agregar más información sobre el Tema 1 -->
       <h2> Estadística descriptiva </h2>
    </div>

  </div>
            <p>
              La Estadística Descriptiva es la rama de la Estadística que provee los métodos 
              para organizar, representar, resumir y analizar la información contenida en un 
              conjunto de datos, ya sean estos datos de muestras o de poblaciones completas.
            </p>
                            <hr>
    <div>
  <h3>1.1 Conceptos básicos de estadística: </h3>

  <ul>

    <li> Definición:  </li>
        <p>
          La Estadística es una disciplina de las Matemáticas que recopila y 
          organiza la información sobre personas, eventos o entidades. Utiliza diversos métodos y 
          técnicas para llevarla a cabo. Además, facilita el análisis e 
          interpretación de estos datos con el objetivo de extraer conclusiones a partir de ellos.
        </p>

    <li> Teoría de decisión:  </li>
        <p>
          Tiene como objetivo saber como utilizar muestras para determinar 
          si una o varias poblaciones poseen características específicas. Asimismo, permite 
          establecer qué tan improbable es que las muestras observadas provengan de una población 
          hipotética determinada, además de contemplar los diferentes tipos de errores que pueden 
          surgir al probar una hipótesis, con el fin de comprender cómo emplear adecuadamente 
          herramientas como las distribuciones de probabilidad durante el proceso.
        </p>

    <li> Población:  </li>
        <p>
          La población se refiere al conjunto completo de elementos sobre los cuales se observan o 
          se estudian una o más características de interés. 
        </p>

    <li> Muestra aleatoria:  </li>
        <p>
          Dado que una muestra se trata de un subconjunto de todos los elementos, una muestra
          aleatoria se trata de una selección de esta muestra donde existe la probabillidad
          de que alguno de estos elementos sea elegido.
        </p>

    <li> Parámetros aleatorios:  </li>
        <p>
          Se refiere a las características que  se pueden medir en la muestra.
        </p>

  </ul>

                  <hr>

  <h3>1.2 Descripción de datos </h3>

  <ul>

    <li> Datos agrupados:  </li>
         <p>
          Para utiizar los datos de una manera más precisa, estos se deben agrupar en Una
          distribución de frecuencias, mediante categorías.
         </p>

    <li> Datos no agrupados:  </li>
         <p>
          Se trata de aquellos datos que no han sido clasificados después de haber sido recolectados.
          No se encuentran ordenados bajo ningún criterrio.
         </p>

    <li> Frecuencia de clase:  </li>
          <p>
            Indica cuántos o qué porcentaje de los datos se encuentran 
            dentro de un rango o intervalo de clase determinado en una representación estadística 
            de datos agrupados.
          </p>

    <li> Frecuencia relativa:  </li>
         <p>
          Se refiere al porcentaje que corresponde a cada valor adentro de un conjunto de datos.
         </p>

    <li> Punto medio:  </li>
         <p>
            También conocido como marca de clase, se trata de la cantidad intermedia que existe entre los  
            valores de cada límite de cada clase. 
         </p>

    <li> Limites:  </li>
         <p>
            Retomando el concepto anterior, los límites se tratan de el valor inferior  y superior
            que existen entre cada clase, donde empieza y termina cada una de ellas.
         </p>

  </ul>

                    <hr>

  <h3>1.3 Medidas de tendencia central </h3>
<p>
  Se trata de medidas de la estadística que se encargan de simplificar un conjunto de valores
  en un solo valor.
</p>
  <ul>

    <li> Media aritmética, geométrica y ponderada:  </li>
        <p>
            La media aritmética es el promedio de la muestra.
            La media geométrica

        </p>

    <li> Mediana:  </li>
        <p>
          Funciona para representa el valor de la variable que ocupa la posición intermedia cuando 
          los datos se ordenan de menor a mayor.
          Cuando el número de elementos a observar se trata de un número par, entonces debemos 
          realizar el promedio de dos de los valores centrales.
        </p>
    <li> Moda:  </li>
        <p>
          Se trata del valor que más se repite en la muestra.
        </p>
    <li> Medidas de dispersión:  </li>
        <p>
          Se trata del rango de valores que una medida estadística puede tomar al ser 
          calculada para distintas muestras o subgrupos de datos.
          Por ejemplo, una medida de dispersión muy utilizada es la varianza o desviación
          estándar.
        </p>
    <li> Varianza:  </li>
        <p>
          Se trata de la variación que pueda tener de los datos del valor de la media.
          Indica qué tan alejados se encuentran dichos valores a la media.
          Esta es la fórmula para obtenerla: 
          
            $$
            \sigma^2 = \sum_{i=1}^{N} (x_i - \mu)^2 P(x_i)
            $$

          Para utilizar esta fórmula se tuvo que haber realizado el cálculo de la fórmula del 
          valor esperado previamente, que corresponde al valor de $$ \mu$$

        </p>
    <li> Desviación estándar:  </li>
        <p>
          Nos indica qué tan dispersos están, en promedio, los valores de datos 
          respecto a la media o valor central de la distribución. A mayor dispersión de los datos, 
          mayor será el valor de la desviación estándar.
          Esta es su fórmula:
          $$
          DE = \sqrt{\frac{\sum |x - \mu|^2}{N}}
          $$

        </p> 
    <li> Desviación media:  </li>
        <p>
          Se trata de una medida que resume el grado de dispersión o variabilidad presente en un 
          conjunto de datos.

          Esta medida representa el promedio de las diferencias absolutas entre cada valor 
          individual y la media del conjunto. Así, cuanto menor sea la desviación media de un 
          grupo de datos, estarán más cercanos entre sí.
          
          Por el contrario, si la desviación media de un conjunto de datos es mayor que la de otro
           conjunto, indica que los valores del primer conjunto presentan una dispersión o mayor, 
           es decir, se encuentran más distantes unos de otros en comparación con el segundo conjunto.
          Esta es su fórmula:
          $$
          DM = \frac{|n_1 - \bar{x}| + |n_2 - \bar{x}| + \cdots + |n_n - \bar{x}|}{N}
          $$

        </p>
    <li> Desviación mediana:  </li>
        <p>
            Es una medida de dispersión estadística que se comporta de manera más robusta que 
            la desviación estándar, especialmente cuando se trabaja con distribuciones de datos 
            que carecen de media o varianza definidas. Esta es su fórmula:

            $$
            DM = \frac{\sum |x_i - Me| \cdot n_i}{n}
            $$
        </p>
    <li> Rango:  </li>
        <p>
          el rango proporciona información sobre la extensión o longitud del intervalo que 
          abarca todos los elementos del conjunto de datos. Se calcula restando el valor mínimo 
          del valor máximo.
        </p>
  </ul>

                      <hr>

  <h3>1.4 Parámetros para datos agrupados </h3>
      <p>
        Se trata de los siguientes parámetros:
          <il>
              <li>Rango.</li>
              <li>Desviación estándar.</li>
              <li>Varianza.</li>
              <li>Desviación media.</li>
              <li>Coeficiente de variación.</li>

          </il>

      </p>
                      <hr>


  <h3>1.5 Distribución de frecuencias </h3>
      <p>
        Se realiza una tabla con los siguientes datos:
        <il>
            <li>Clases.</li>
            <li>Límites inferiores.</li>
            <li>Límites superiores.</li>
            <li>Marca de clase.</li>
            <li>Frecuencia absoluta.</li>
            <li>Frecuencia relativa.</li>
            <li>Frecuencia acumulada.</li>

        </il>
      </p>

                      <hr>      

  <h3>1.6 Técnicas de agrupación de datos </h3>
      <p>
        corresponde a la organización de datos estadísticos de acuerdo a la clase y su respectiva
        frecuencia, entre estos datos se forma un solo intervalo de clase. No hay una manera 
        establecida para utilizar datos agrupados o no agrupados, pero existe la sugerencia de 
        que cuando la cantidad de datos supere los 50 y el valor del rango sea mayor a 20, entonces
        se utiliza una distrib de frecuencias con datos agrupados. También se recomienda usar esta
        misma distribución cuando sea necesario elaborar gráficos como histogramas, polígonos
        de frecuancias y ojivas.
      </p>

                      <hr>

  <h3>1.7 Técnicas de muestreo </h3>
      <p>
Los dos principales métodos son: 

Muestreo no aleatorio o de juicio
      <ul>
        <li>Está basado en el criterio de alguien familiarizado con la población.</li>
        <li>La muestra no se realiza mediante el azar.</li>
      </ul>

Muestreo aleatorio
      <ul>
        <li>Para seleccionar la muestra se realiza mediante el azar.</li>
        <li>Tiene la posibilidad de ser seleccionado cada elemeto de la población</li>
      </ul>

      </p>

      <p>Actividad en equipo: </p> <br>
      
      <span class="resaltado">Trabajo en equipo.</span> <br>
      <a href="ternura.html">Acceder</a>


</div>


<br>
<br>
<br>
<br>
<br>


<div class="window">
    <h1 id="tema2">Tema 2</h1>

    <div class="content">
      <!-- Aquí puedes agregar más información sobre el Tema 1 -->
       <h2> Fundamentos de la Teoría de Probabilidad. </h2>
    </div>
    
  </div>

  <div>

    <a href="TEMAS.html">Regresar al índice</a> 

    <h3>2.1 Técnicas de Conteo. </h3>
  Se trata de procesos y fórmulas que nos da la posibilidad de obtener el total de resultados posibles
  en un experimento.
  
  
  
    <ul>
  
      <li> 2.1.1 Principio aditivo: </li>
  
            <p>
              Si tenemos dos eventos independientes y alternativos, donde el primero puede suceder de 
              "m" maneras distintas y el segundo puede ocurrir de "n" formas diferentes, y ambos 
              eventos son mutuamente excluyentes, entonces el número total de combinaciones posibles 
              para que ocurra el evento "A" o el evento "B" es el resultado de sumar "m" y "n".
  
            </p>
  
      <li> 2.1.2 Principio multiplicativo:  </li>
  
            <p>
              Si dos eventos independientes donde el primero puede suceder de "m" maneras 
              distintas y el segundo puede ocurrir de "n" formas diferentes, entonces el número total 
              de combinaciones posibles para que ambos eventos ocurran es el resultado de multiplicar 
              "m" por "n".
            </p>
  
      <li> 2.1.3 Notación Factorial: </li>
  
          <p>
              Se trata de una función matemática que se representan con el símbolo !
              Es el resultado de multiplicar todos los números positivos y enteros que van desde
              1 hasta n cantidad.
          </p>
  
      <li> 2.1.4 Permutaciones:  </li>
  
      <p>
        En otras palabras, el número de permutaciones representa la cantidad de maneras únicas en que 
        se pueden colocar o disponer r elementos seleccionados de un conjunto original de n elementos, 
        donde el orden de selección es relevante.
  
        $$
          \text{nPr} = \frac{n!}{(n-r)!}
          $$
      </p>
  
      <li> 2.1.5 Combinaciones:  </li>
  
      <p>
        Se trata de la cantidad de formas en las que se pueden elegir r objetos de un conjunto que 
        contiene n elementos, sin considerar el orden de selección, se denomina número de combinaciones
        de n objetos tomados de r en r.
  
  
        $$
          \text{nCr} = \frac{n!}{r!(n-r)!}
          $$
      </p>
  
      <li> 2.1.6 Diagrama de Árbol:  </li>
  
      <p>
        Se trata de un método gráfico con el que podemos ver los resultados posibles de un
        experimento.
      </p>
      <img src="imagen/featured.jpg" alt="D" width="200" height="100">
  
      <li> 2.1.7 Teorema del Binomio:  </li>
  
      <p>
        Describe la forma de expandir una expresión binomial, es decir, una expresión que consta 
        de la suma de dos términos elevada a una potencia entera positiva. <br>
        Su fórmula es:
        $$
        a + b)^n = \sum_{k=0}^n \frac{n!}{k!(n-k)!} a^{n-k} b^k
        $$

      </p>

    </ul>
  
  <hr>
  
    <h3>2.2 Teoría elemental de probabilidad. </h3>
  
        <p>
          Busca atribuir un número a cada posible resultado de un 
          experimento aleatorio, de manera que se pueda medir y comparar la probabilidad de que 
          ocurra cada uno de esos resultados. Esto permite entender qué eventos son más o menos 
          probables de ocurrir.
        </p>
  
  <hr>
  
    <h3>2.3 Probabilidad de Eventos: </h3>
  
    <ul>
  
      <li> Definición de espacio muestral:  </li>
  
      <p>
        el espacio muestral representa el conjunto completo de todas las posibles opciones o 
        alternativas que pueden generarse como consecuencia de la realización de un experimento 
        aleatorio. Incluye cada uno de los resultados individuales y mutuamente excluyentes que 
        pueden obtenerse.
      </p>
  
      <li> Definición de evento:  </li>
          <p>
            Un evento corresponde a cualquier resultado factible que puede obtenerse de un experimento,
           y es la unidad mínima de análisis utilizada para efectuar los cálculos de probabilidades.
          </p>
      <li> Simbología:  </li>
          <p>
              <ul>
                <li>Espacio muestral: omega (Ω) o "S".</li>
                <li>Evento: Se representa con letras como A, B, C, etc.</li>
                <li>Probabilidad: De un evento P(A)</li>
              </ul>
          </p>
      <li> Unión:  </li>
            <p>
              Unión de sucesos: La unión de dos eventos A y B se refiere al evento compuesto por 
              todos los resultados o sucesos elementales que forman parte de A, de B, o de ambos 
              A y B a la vez. Este evento unión se representa simbólicamente como A ∪ B.
            </p>
      <li> Intersección:  </li>
           <p>
            Intersección de sucesos: la intersección de dos eventos A y B se refiere al evento 
            compuesto por todos los resultados o sucesos elementales que son comunes a ambos 
            eventos A y B. Este evento de intersección se representa simbólicamente como A ∩ B.
           </p>   
      <li> Diagramas de Venn:  </li>
           <p>
            los diagramas de Venn son útiles para mostrar cómo los elementos pueden pertenecer a 
            múltiples categorías simultáneamente, y permiten representar gráficamente las 
            interrelaciones entre los diferentes conjuntos o categorías que componen un determinado 
            universo de análisis.
           </p>
           <img src="imagen/venn.jpg" alt="D" width="400" height="100">
  
           <p>
            Operaciones utilizadas para emplear eventos aleatorios.
           </p>
           <img src="imagen/tablaVenn.jpg" alt="D" width="600" height="200">
    </ul>
  
  
  <hr>
  
    <h3> 2.4 Probabilidad con Técnicas de Conteo:  </h3>
    <ul>
  
      <li> Axiomas:  </li>
  
          <p>
            los axiomas de probabilidad son las condiciones básicas que debe cumplir una función de 
            probabilidad definida sobre un conjunto de eventos, de modo que las probabilidades que 
            ésta asigna a dichos eventos sean consistentes y tengan sentido.
  
            La probabilidad de un suceso:
            <ul>
              <li>Axioma 1: No puede ser negativa.</li>
              <li>Axioma 2: Es de 1.</li>
              <li>Axioma 3: si tenemos un grupo de eventos que no pueden ocurrir simultáneamente, 
                es decir, son eventos excluyentes entre sí, entonces la probabilidad del conjunto 
                completo de esos eventos es simplemente la adición de las probabilidades de cada 
                evento individual.
  
              </li>
            </ul>
          </p>
  
      <li> Teoremas:  </li>
          <p>
            Supongamos que P(A) y P(B) representan las probabilidades de los eventos A y B, 
            respectivamente. Entonces, P(A ∪ B) significa la probabilidad de que ocurra el evento
             A o el evento B, o ambos.
  
            Si representamos los eventos A y B en un diagrama de Venn:
          </p>
          <img src="imagen/diagramaVenn.jpg" alt="D" width="300" height="200">
  
          <p>
            Cuando los eventos A y B se representan como conjuntos separados que no se superponen 
            en un diagrama de Venn, esto indica que son eventos mutuamente excluyentes, que no pueden 
            suceder al mismo tiempo.
          </p>
  
          <img src="imagen/ABunion.jpg" alt="D" width="250" height="100">
  
            <p>
              Si los dos eventos tienen puntos muestrales en los que ambos coinciden
            </p>
  
            <img src="imagen/dvn.jpg" alt="D" width="300" height="200">
  
    </ul>
  
  <hr>
  
    <h3>2.5 Probabilidad condicional: </h3>
      <p>
        Nos permite calcular la probabilidad de que un evento suceda, cuando otro evento 
        ha ocurrido antes. <br>
  Para algunos casos, se necesita calcular la probabilidad condicional condicionada, es decir, 
  la probabilidad de un evento dado que otro evento ha ocurrido y se sabe que está relacionado 
  con un tercer evento.
  
      </p>
  
    <ul>
  
      <li> Dependiente:  </li>
          <p>
            Implica que la probabilidad de un evento B no es independiente, sino que está ligado
            a la previa ocurrencia del evento A. Existe una relación de dependencia entre las 
            probabilidades de ambos eventos.
          </p>
      <li> Independiente:  </li>
          <p>
            Cuando la probabilidad de un evento B es independiente de si el evento A ha ocurrido 
            o no, se dice que la probabilidad de B es condicionalmente independiente de A.
          </p>
    </ul>
  
  <hr>
  
    <h3>2.6 Ley multiplicativa. </h3>
        <p>
          Si los eventos A y B son independientes entre sí, la probabilidad de que ocurran los dos 
          eventos de forma conjunta se calcula multiplicando la probabilidad del evento A por la 
          probabilidad del evento B.
        </p>
  
        $$
        P(A \cap B) = p(A) \cdot p(B)
        $$
        <p>
          No puede ser válida para eventos que dependen entre sí.
  
        </p>
  
  <hr>
  
    <h3>2.7 Eventos independientes: Regla de Bayes. </h3>
        <p>
        De esta manera, el Teorema de Bayes nos permite realizar inferencias y actualizaciones en 
        nuestras estimaciones de probabilidad a medida que tenemos acceso a nueva información 
        pertinente. Esto hace que sea una herramienta estadística muy útil para la toma de decisiones.
          <br>
        Se debe tener en cuenta conceptos básicos como: La probabilidad condicional, la regla
        de multiplicación de la probabilidad. Se basa principalmente en ellos.
        El Teorema de Bayes establece la forma de calcular la probabilidad condicional de un evento 
        A, dado que ha ocurrido otro evento B, utilizando las probabilidades individuales de A y B, 
        y la probabilidad condicional de B dado A.
        </p>
        $$
        P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
        $$

        <span class="resaltado">Trabajo en equipo.</span> <br>
      <a href="Ejercicios.html"> Acceder.</a>
    
      
        
  </div>
  
 


  <br>
  <br>
  <br>
  <br>
  <br>
  
  
  <div class="window">
    <h1 id="tema3">Tema 3</h1>
  
      <div class="content">
        <!-- Aquí puedes agregar más información sobre el Tema 1 -->
         <h2> Variables aleatorias. </h2>
      </div>
  
    </div>

   

</div>



<p>
    Una variable aleatoria es una función que se determina mediante el resultado de un 
    experimento donde se obtienen resultados aleatorios. 

</p>

<div>

  
  <a href="TEMAS.html">Regresar al índice</a>
<h3>3.1 Variables aleatorias discretas: </h3>



    <p>
        Representa a un número de valores que se puedan numerar en un rango específico 
        ya que se trata de una cantidad finita de estos valores. 
        Hay que considerar que estos números son enteros.
    </p>

<ul>

<li> 3.1.1 Distribución de probabilidad en forma general: </li>
    <p>
      Se va a representar mediante la función de masa de probabilidad (PMF).
      Se denotada como p(x), de una variable aleatoria discreta X es la siguiente:
      $$
      p(x) = P(X = x)
      $$

      Cuenta con las siguientes propiedades:
      <ul>
        <li>La probabilidad de que una variable aleatoria discreta tome un cierto valor nunca 
          puede ser un número negativo. La probabilidad siempre toma valores entre 0 y 1.
        </li>

        <li>
          Si se suman todas las probabilidades de los diferentes valores que puede asumir la 
          variable aleatoria, el resultado será 1. Esto se expresa matemáticamente como:
          Σ p(x) = 1
        </li>
      </ul>

    </p>

<li>3.1.2 Valor esperado:</li>
    <p>
      El valor esperado o media para este caso, se representa como E(X). Se trata del 
      promedio de la variable aleatoria, ponderando cada posible valor por su probabilidad 
      de ocurrencia. <br>
      Esta es la fórmula:
      $$
      \mu = E(X) = x_1 \cdot f(x_1) + x_2 \cdot f(x_2) + \dots + x_n \cdot f(x_n) = \sum x \cdot f(x)
      $$
    </p>

<li> 3.1.3 Varianza, desviación estándar: </li>
    <p>
      <ul>
        <li>
          La varianza, denotada por el símbolo "σ²" o "V(X)", es una medida de dispersión que 
      representa un promedio ponderado de los cuadrados de las desviaciones de una variable 
      aleatoria con respecto a su media. <br>
      Esta es su fórmula:
      $$
      \sigma^2 = V(X) = \left[\sum x^2 \cdot f(x)\right] - \mu^2
      $$
        </li>

        <li>
          Desviación estándar: Se denota por el símbolo "σ"  y se trata de la raíz cuadrada 
          positiva de la varianza. <br>
          Esta es la fórmula:
          $$
          \sigma = \sqrt{\sigma^2}
          $$
        </li>

      </ul>
      
      

    </p>



<li>3.1.4 Función acumulada: </li>
    <p>
      La función de distribución acumulativa permite calcular la probabilidad de que una 
      variable aleatoria X tome un valor menor o igual a un valor específico x. Esta función 
      proporciona información sobre la probabilidad acumulada de los posibles valores que puede 
      tomar la variable aleatoria. <br>
      Su fórmula es: 
      $$
      F(x) = P(X \leq x)
      $$

      propiedades:
      <ul>
        <li>Valores del intervalo F(x): 0 ≤ F(x) ≤ 1</li>
        <li>F(x) no se trata de una función que decrece.</li>
      </ul>

      Para la variable aleatoria discreta se cumple:
      $$
      P(a < X \leq b) = F(b) - F(a)
      $$
    </p>

</ul>

<br>
<br>
<br>

<hr>

<h3>3.2 Variables aleatorias Continuas: </h3>
 <p>
    Representa a un número de valores que no se pueden numerar con precisión dentro de un rango
    específico. Estos valores están formados por números decimales.
    
 </p> 

<ul>

<li> 3.2.1Distribución de probabilidad en forma general:  </li>
    <p>
      Se va a representar mediante la función de densidad de probabilidad (PDF). <br>
      La función de densidad de probabilidad f(x) representa la razón de cambio instantánea 
      (la derivada) de la función de distribución acumulativa F(x) con respecto al valor x de 
      la variable aleatoria continua.
      Esta es su fórmula:
      $$
      f(x) = \frac{dF(x)}{dx}
      $$
      <p>
        Cumple con estas propiedades:
        <ul>
          <li>
            El valor de la función f(x) es siempre mayor o igual a cero para cualquier valor 
            de x. Es decir, f(x) ≥ 0 para todo x.
          </li>
          <li>
            La integral de la función de densidad de probabilidad f(x) evaluada en todo el 
            rango de valores posibles de x, desde menos infinito (-∞) hasta más infinito (+∞),
             es igual a 1.
          </li>
        </ul>

      </p>

    </p>
<li> 3.2.2 Valor esperado:  </li>
    <p>
      Al igual que en la variable aleatoria discreta, se utiliza la media, es decir,
      μ o E(X). <br>
      Su fórmula es la siguiente:
      $$
      \mu = E(X) = \int_{-\infty}^{\infty} x \cdot f(x) dx
      $$
    </p>
<li> 3.2.3 Varianza, desviación estándar:  </li>
    <p>
      <ul>
        <li>La varianza igual se representa como σ² o V(X) tal como en las variables
          aleatorias discretas. <br>
          Su fórmula es la siguiente:
          $$
          \sigma^2 = V(X) = \int_{-\infty}^{\infty} x^2 \cdot f(x) dx - \mu^2
          $$

        </li>
      </ul>
    </p>
<li> 3.2.4 Función acumulada:  </li>
    <p>
      La función de distribución acumulativa nos proporciona la probabilidad de que la variable 
      aleatoria tome un valor menor o igual a un valor dado "x". <br>
      Su fórmula es la siguiente:
      $$
      F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t)dt
      $$

    </p>
<li> 3.2.5 Cálculos de probabilidad:  </li>
    <p>
      Es necesario tener en cuenta lo siguiente para realizar los cálculos de probabilidad: <br>
      Función de Distribución Acumulativa (CDF): <br>
      La función de distribución acumulativa F(x) es una herramienta fundamental para realizar 
      cálculos de probabilidad con variables aleatorias continuas, ya que permite determinar 
      las probabilidades de que X tome valores en un intervalo específico. <br>
      A partir de la CDF, es posible calcular P(a ≤ X ≤ b) = F(b) - F(a).
      Cálculo de probabilidades: <br>
      El cálculo de probabilidades con variables aleatorias continuas se basa en la integración 
      de la función de densidad de probabilidad para determinar probabilidades en intervalos, 
      así como en el uso de la función de distribución acumulativa para calcular probabilidades 
      de valores específicos. <br>
      <br>
      <br>


    </p>
</ul>

<br>
<br>
<span class="resaltado">Actividades del tema.</span> 
<br>

<ul>
  <li>
    <a href="https://www.canva.com/design/DAGJ0inzMPQ/jDNzupqyep31Z4bs08z_Tg/watch?utm_conte
    nt=DAGJ0inzMPQ&utm_campaign=designshare&utm_medium=link&utm_source=editor"> Variable aleatoria continua.</a>
  </li>
  <li>
    <a href="https://www.canva.com/design/DAGJ0pSzuNc/zGegzkFCkMvt-xFsoEhWQA/watch?utm_con
    tent=DAGJ0pSzuNc&utm_campaign=designshare&utm_medium=link&utm_source=editor">Variable aleatoria discreta.</a>
  </li>
</ul>



</div>

<br>
<br>
<br>
<br>
<br>


<div class="window">
    <h1 id="tema4">Tema 4</h1>

    <div class="content">
      <!-- Aquí puedes agregar más información sobre el Tema 1 -->
       <h2> Distribuciones de probabilidad. </h2>
    </div>

  </div>



</div>

<p>
    Las distribuciones de probabalidad son los valores que podrían resultar de
    un experimento con resultados aleatorios, más la probabilidad que cada valor 
    tiene y su respectiva distribución de frecuencias.
</p>


<div>
  <a href="TEMAS.html">Regresar al índice</a>
<h3>4.1 Función de probabilidad: </h3>
<p>
La función de probabilidad es una fórmula matemática que indica la probabilidad 
de que una variable aleatoria discreta asuma un valor determinado. Esta función 
asigna a cada posible valor de la variable una probabilidad que cumple con las 
propiedades fundamentales de las probabilidades.
</p>

<hr>

<p>Antes de continuar es importante mencionar  primero: </p>
<p>
<span class="resaltado">Proceso de bernouilli.</span>
<ul>
    <li>   
        Solo es posible obtener dos resultados: Éxito o fracaso.
    </li>

    <li>  
        Cada resultado obtenido de éxito o fracaso es independiente de los demás resultados.
    </li>

    <li>
        Para los resultado tanto de éxito como de fracaso, su probabilidad se mantendrá 
        constante.
    </li>
  </ul>

<p>
    <p>P(E) = p</p>
        <span>p = probabilidad</span>
        <br>
        <span>E = éxito</span>
</p>
<br>
<p>
    <p> P(F) = p </p>
        <span>p = probabilidad</span>
        <br>
        <span>F = fracaso</span>
</p>
 
<br>
<p> Tomando en cuenta a la variable aleatoria: </p>
<p> xi = 1 para el resultado con éxito </p>
<p> xi = 0 si el resultado es fracaso </p>
<p> De modo que: </p>
<p> P(E) = P(X=1) = p</p>
<p> P(F) = P(X=0) = q </p>

<p>Entonces: </p>
<p> q = 1-p </p>

</p>

<hr>

<h3> 4.2 Distribución binomial: </h3>

<p>Se trata de una distribución discreta.</p>
<p>Comparte las mismas características del proceso o ensayo de Bernouilli.</p>
<p> Se puede representar con B, teniendo como parámetros n y p.</p>   
<p>
Su fórmula es la siguiente:
$$
f(k; n, p) = \binom{n}{k} p^k (1 - p)^{n-k}
$$

Para obtener la media es:
$$
np
$$

Para obtener su varianza es:
$$
np(1 - p)
$$
</p> 


<hr>

<h3> 4.3 Distribución hipergeométrica: </h3>
<p>
Se utiliza cuando un muestreo no puede ser reemplazado de una población finita.
Su fórmula es la siguiente: 
$$
f(k; N, n, K) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}
$$
<br>
Su fórmula para obtener su media es:
$$
\frac{nK}{N}
$$

Y para obtener su varianza es la siguiente:
$$
\frac{nK(N-K)(N-n)}{N^2(N-1)}
$$
</p>

<hr>

<h3> 4.4 Distribución de Poisson: </h3>
<p>
<ul>
    <li>
        Se trata de una distribución discreta.
    </li>
    <li>
        Se utiliza para determinar la cantidad de hechos generados en un intervalo
        de tiempo o espacio.
    </li>
</ul>
</p>


<p>Su fórmula es la siguiente: </p>
$$
f(k; \lambda) = \frac{e^{-\lambda}\lambda^k}{k!}
$$

<p>Lambda = número promedio de eventos por cada tiempo definido</p> <br>
<p>
    Se obtiene su media mediante:
</p>
$$
\lambda
$$
<p>
    Se obtiene su varianza mediante:
</p>
$$
\lambda
$$
<hr>

<h3> 4.5 Distribución normal: </h3>
<p>
Consiste en los casos que destacan sobre una cantidad de diversos casos al azar ya
que se obtienen características peculiares y es eso precisamente lo que la 
distribución normal puede obtener.            
</p>
<p>La función para esta distribución tiene forma de campana.</p>
<p>Tiene como características:</p>

<p>
<ul>
    <li>Ser simétrica.</li>
    <li>Los valores de sus extremos tienen a infinito y nunca tocan el eje x.</li>
    <li>Al centro de la curva podemos encontrar la media, mediana y moda.</li>
    <li>Se centra en la media y la varianza.</li>
</ul>
</p>
<p>
Su fórmula es la siguiente:
$$
f(x; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
<br>
Su media se calcula como:
$$
\mu
$$

Su varianza se calcula como:
$$
\sigma^2
$$
</p>


<hr>
<h3> 4.6 Distribución T-student: </h3>
<p>Se utiliza cuando los tamaños de las muestras son pequeñas. </p>
<p>
<ul>
    <li>Al igual que la distribución normal, es simétrica.</li>
    <li>Es menos receptivo a datos irregulares.</li>
    <li>Su parámetro es el número de grados de libertad (df)</li>
</ul>
</p>

<p>
El funcionamiento de la distribución t se fundamenta en la relación entre la media 
de una muestra y la media de la población, ajustada según el tamaño de la muestra y 
la varianza poblacional desconocida. La fórmula general para la distribución t es 
la siguiente:

</p>
<img src="https://elmundodelosdatos.com/wp-content/uploads/2023/10/formulat.jpg" alt="D" width="100" height="50">


<hr>
<h3> 4.7 Distribución Chi cuadrada: </h3>
<p>Se emplea para el anális de datos de dos o más varibales, las variables son
cualitativas. Interpreta la relación que hay entre estas variables y la comprobación
de hipótesis.
</p>

<p>
El parámetro de grados de libertad generalmente es un número entero, aunque las funciones 
chi-cuadrado admiten cualquier valor positivo.


</p>
<p>
Su función de densidad de probabilidad (pdf) es:
</p>
<img src="imagen/chi.jpg" alt="D" width="200" height="100">


<hr>
<h3> 4.8 Distribución F:</h3>
<p>
Se emplea para comparar varianzas entre poblaciones y determinar si la diferencia 
observada entre dos grupos se debe al azar o a factores significativos. Se define 
como la distribución de la razón de dos variables aleatorias, ambas con distribuciones 
chi-cuadrado, ajustadas por sus respectivos grados de libertad.

</p>
<p>
La variable aleatoria F se define como el cociente de dos variables aleatorias 
ji-cuadrada independientes, cada una dividida entre sus respectivos grados de libertad. 
Esto es:
</p>

<img src="imagen/f.jpg" alt="D" width="200" height="100">
<br>

<br>
<br>
<span class="resaltado">Actividades del tema.</span> 
<br>
<a href="https://www.canva.com/design/DAGJ0JoG38Q/PODrHLdYOPOc_yaVcMxKTA/watch?utm_c
ontent=DAGJ0JoG38Q&utm_campaign=designshare&utm_medium=link&utm_source=edito
r">Explicación tema 4</a>

</div>

<br>
<br>
<br>
<br>
<br>


<div class="window">
    <h1 id="tema5">Tema 5</h1>

    <div class="content">
      <!-- Aquí puedes agregar más información sobre el Tema 1 -->
       <h2> Regresión lineal. </h2>
    </div>

  </div>
  
  <div>
<p>
    Se trata de una técnica que nos permite conocer un valor desconocido de acuerdo a otro ya
    conocido, se trata de predecir este valor mediante un análisis de datos.
</p>
<a href="TEMAS.html">Regresar al índice</a>
    <h3>5.1 Regresión y correlación: </h3>
          <p>
              Primero debemos entender que la correlación consiste en la manera en la que podemos 
              relacionar las variables y la regresión se trata del modelado que nos permite 
              realizar una ecuación mediante la cual nos permitirá obtener el valor de una de 
              ellas gracias a la otra variable o al conjunto que hay entre estos dos valores.



          </p>
  
    <ul>
  
      <li>5.1.1 Diagrama de dispersión. :</li>
          <p>
            Se utiliza para analizar y representar gráficamente la relación que hay entre los 
            valores de ambas variables. <br>

            Ejemplo: <br>
            <img src="imagen/RLdiagrama.jpg" alt="D" width="600" height="200">

          </p>
  
      <li>5.1.2 Regresión lineal simple:</li>
          <p>
            La regresión lineal tiene como objetivo establecer una relación de tipo lineal entre una 
            variable independiente y su correspondiente variable dependiente. No obstante, no es 
            posible trazar una línea recta que pase exactamente por todos los puntos de un gráfico 
            que presenta una distribución desordenada. <br>

            Por lo tanto, en el proceso de regresión lineal, se determina la ubicación óptima de la 
            línea recta que mejor se ajuste a los datos disponibles. Esto se logra minimizando la 
            distancia de los puntos a dicha línea recta. Aun así, algunos puntos seguirán estando 
            alejados de la línea, pero esta distancia debe ser la menor posible. <br>
            
            El cálculo de esta distancia mínima de cada punto a la línea recta se denomina función de 
            pérdida. Esta función permite evaluar la calidad del ajuste lineal realizado a los datos.
                <br>
            Esta es su fórmula:
            $$
            Y = \beta_0 + \beta_1 X + \epsilon
            $$
          </p>
  
      <li>5.1.3 Correlación:</li>
          <p>
            La correlación mide únicamente la relación entre las dos variables, sin considerar 
            si hay una dependencia entre ellas.
            Se emplea cuando ninguna de las variables ha sido controlada o manipulada 
            deliberadamente. En estos casos, simplemente se miden ambas variables para determinar 
            si existe alguna relación entre ellas.
          </p>
  
      <li>5.1.4 Determinación y análisis de los coeficientes 
          de correlación y de determinación:</li>
          <p>
            El coeficiente de correlación lineal es una medida que cuantifica el grado de relación o 
            intensidad existente entre dos variables. Este coeficiente nos informa que la asociación 
            entre las variables es de naturaleza lineal, es decir, que se puede representar mediante una 
            línea recta.
            No obstante puede haber casos en los que la relación entre las variables
             no sea de tipo lineal, sino que adopte otras formas funcionales, como exponencial o parabólica.
              En estas situaciones, el coeficiente de correlación lineal no sería el más adecuado, ya que 
              no lograría captar correctamente la intensidad de la relación entre las variables.
          </p>
  
      <li>5.1.5 Distribución normal bidimensional:</li>
          <p>
            se asume que los pares de valores de las variables independiente (x) y dependiente (y) 
            siguen conjuntamente una distribución normal o gaussiana. Esto implica dos cosas:
            Primero, se supone que los errores o residuos del modelo (la diferencia entre los 
            valores observados y los predichos) tienen una distribución normal. <br>
            Y segundo, se considera que la distribución conjunta de los pares de valores (x, y) 
            sigue una distribución normal bidimensional.

          

          </p>
  
    </ul>
  
  </div>




</body>
</html>